/* groovylint-disable DuplicateListLiteral, DuplicateStringLiteral, LineLength, NestedBlockDepth, VariableTypeRequired */
pipeline {
    agent any

    environment {
        // Credentials
        AWS_ACCESS_KEY_ID = credentials('aws-access-key-id')
        AWS_SECRET_ACCESS_KEY = credentials('aws-secret-access-key')
        AWS_ACCOUNT_ID = credentials('aws-rahul-account-id')
        EC2_INSTANCE = credentials('aws-app-server-1-user-with-ip')
        ECR_REPOSITORY = 'red-carpet'
        GITHUB_PAT = credentials('hrms-git-token')
        CODEBUILD_PROJECT_NAME = 'RED-CARPET-Build'
        AWS_REGION = 'ap-south-1'

        // GIT
        // (Using GITHUB_PAT in the URL)
        GIT_REPO = "https://${GITHUB_PAT}@github.com/sameersharma6261/red-carpet.git"

        // Production ports
        FRONTEND_PORT = '3700'
        FRONTEND_SECONDARY_PORT = '3701'
        BACKEND_PORT = '5700'
        BACKEND_SECONDARY_PORT = '5701'
        // Staging ports
        STAGING_FRONTEND_PORT = '4700'
        STAGING_FRONTEND_SECONDARY_PORT = '4701'
        STAGING_BACKEND_PORT = '6700'
        STAGING_BACKEND_SECONDARY_PORT = '6701'

        // Workspace and health checks
        BASE_DIR = '/home/ubuntu/red-carpet'
        HEALTH_BACKEND_PATH = 'api/health'
        HEALTH_FRONTEND_PATH = 'health'

        JENKINS_EC2_APP_SERVER_TWO = 'jenkins-ssh-key'
        // Nginx conf files
        NGINX_STAGING_CONF = 'redcarpet.qrblack.com.conf'
        NGINX_PRODUCTION_CONF = 'redcarpet.qrblack.com.conf'
        APP_NAME = 'red-carpet'

        // S3 bucket for your env files
        S3_ENV_BUCKET = 'secure-env-files-itsoftlab'
        // Frontend keys
        FRONTEND_PRODUCTION_ENV_S3_KEY  = 'red-carpet-frontend-production-env'
        FRONTEND_STAGING_ENV_S3_KEY     = 'red-carpet-frontend-staging-env'

        // Backend keys
        BACKEND_PRODUCTION_ENV_S3_KEY   = 'red-carpet-backend-production-env'
        BACKEND_STAGING_ENV_S3_KEY      = 'red-carpet-backend-staging-env'
    }

    stages {
        stage('Validate Git Tag') {
            steps {
                script {
                    // Use tag(s) pointing at HEAD to avoid picking an unrelated latest tag
                    env.TAG_NAME = sh(script: 'git tag --points-at HEAD || echo ""', returnStdout: true).trim()

                    if (!env.TAG_NAME) {
                        error '‚ùå No tag detected! Deployment only triggers on tag creation.'
                    }
                    echo "üìå Detected Tag: ${env.TAG_NAME}"

                    // Extract branch from which the tag originated.
                    env.BRANCH = sh(script: "git branch -r --contains ${env.TAG_NAME} | grep -Eo 'origin/(main|staging|hotfix)' | head -n 1 | cut -d '/' -f2 || echo ''", returnStdout: true).trim()
                    if (!env.BRANCH) {
                        error "‚ùå Invalid tag! Tags must be from 'main', 'staging', or 'hotfix' branches."
                    }

                    if (env.BRANCH == 'main' && env.TAG_NAME ==~ /^v\d+\.\d+\.\d+$/) {
                        env.ENVIRONMENT = 'production'
                    } else if (env.BRANCH == 'staging' && env.TAG_NAME ==~ /^v\d+\.\d+\.\d+-staging$/) {
                        env.ENVIRONMENT = 'staging'
                    } else if (env.BRANCH == 'hotfix' && env.TAG_NAME ==~ /^hotfix-\d+\.\d+\.\d+$/) {
                        env.ENVIRONMENT = 'production'
                    } else {
                        error "‚ùå Invalid tag format for branch '${env.BRANCH}'."
                    }
                    echo "üåç Deployment Environment: ${env.ENVIRONMENT}"
                }
            }
        }

        stage('Create Docker Tags') {
            steps {
                script {
                    env.FRONTEND_TAG = "frontend-${env.ENVIRONMENT}-${env.TAG_NAME}"
                    env.BACKEND_TAG = "backend-${env.ENVIRONMENT}-${env.TAG_NAME}"
                    echo "üõ†Ô∏è Frontend Tag: ${env.FRONTEND_TAG}"
                    echo "üõ†Ô∏è Backend Tag: ${env.BACKEND_TAG}"
                }
            }
        }

        stage('Determine secret key file') {
            steps {
                script {
                    // Determine which S3 keys to use based on the environment
                    if (env.ENVIRONMENT == 'production') {
                        env.FRONTEND_SECRET_KEY = "${env.FRONTEND_PRODUCTION_ENV_S3_KEY}.env"
                        env.BACKEND_SECRET_KEY = "${env.BACKEND_PRODUCTION_ENV_S3_KEY}.env"
                    } else {
                        env.FRONTEND_SECRET_KEY = "${env.FRONTEND_STAGING_ENV_S3_KEY}.env"
                        env.BACKEND_SECRET_KEY = "${env.BACKEND_STAGING_ENV_S3_KEY}.env"
                    }
                }
            }
        }
        stage('Check and Trigger AWS CodeBuild') {
            steps {
                script {
                    echo "üöÄ Checking if images exist in ECR for tags: ${env.FRONTEND_TAG}, ${env.BACKEND_TAG}"
                    def frontendExists = sh(script: """
                        aws ecr describe-images --repository-name ${ECR_REPOSITORY} \
                        --image-ids imageTag=${env.FRONTEND_TAG} \
                        --region ${AWS_REGION} > /dev/null 2>&1
                        """, returnStatus: true) == 0
                    def backendExists = sh(script: """
                        aws ecr describe-images --repository-name ${ECR_REPOSITORY} \
                        --image-ids imageTag=${env.BACKEND_TAG} \
                        --region ${AWS_REGION} > /dev/null 2>&1
                    """, returnStatus: true) == 0

                    if (frontendExists && backendExists) {
                        env.BUILD_ID = 'SKIPPED'
                        echo '‚úÖ Both images already exist in ECR. Skipping CodeBuild trigger.'
                    } else {
                        echo 'üöÄ Triggering AWS CodeBuild for missing images...'
                        env.BUILD_ID = sh(script: """
                            aws codebuild start-build --project-name ${CODEBUILD_PROJECT_NAME} \
                            --region ${AWS_REGION} \
                            --source-version ${env.TAG_NAME} \
                            --environment-variables-override \
                                name=TAG_NAME,value='${env.TAG_NAME}',type=PLAINTEXT \
                                name=ENVIRONMENT,value='${env.ENVIRONMENT}',type=PLAINTEXT \
                                name=FRONTEND_TAG,value='${env.FRONTEND_TAG}',type=PLAINTEXT \
                                name=BACKEND_TAG,value='${env.BACKEND_TAG}',type=PLAINTEXT \
                                name=FRONTEND_SECRET_KEY,value='${env.FRONTEND_SECRET_KEY}',type=PLAINTEXT \
                            --query 'build.id' --output text
                        """, returnStdout: true).trim()
                        if (!env.BUILD_ID?.trim()) {
                            error '‚ùå AWS CodeBuild failed to start. No BUILD_ID received.'
                        }
                        echo "Build started with ID: ${env.BUILD_ID}"
                    }
                }
            }
        }

        stage('Wait for AWS CodeBuild Completion') {
            when {
                expression { env.BUILD_ID && env.BUILD_ID != 'SKIPPED' }
            }
            steps {
                script {
                    echo '‚è≥ Waiting for AWS CodeBuild to complete...'
                    def buildStatus = ''
                    def logStreamName = sh(script: """
                        aws codebuild batch-get-builds --ids ${env.BUILD_ID} --region ${AWS_REGION} \
                        --query 'builds[0].logs.streamName' --output text
                    """, returnStdout: true).trim()

                    if (!logStreamName) {
                        error '‚ùå Unable to fetch CloudWatch Log Stream for CodeBuild.'
                    }
                    echo "üîó Streaming logs from CloudWatch Log Group: /aws/codebuild/${env.CODEBUILD_PROJECT_NAME}"
                    echo "üìÑ Log Stream Name: ${logStreamName}"
                    def nextToken = ''

                    while (!['SUCCEEDED', 'FAILED', 'STOPPED', 'FAULT', 'TIMED_OUT'].contains(buildStatus)) {
                        sleep 10
                        def logCommand = """
                            aws logs get-log-events --log-group-name "/aws/codebuild/${env.CODEBUILD_PROJECT_NAME}" \
                            --log-stream-name "${logStreamName}" --region ${AWS_REGION} --output json \
                            ${nextToken ? "--next-token '${nextToken}'" : ''}
                        """
                        def logResult = sh(script: logCommand, returnStdout: true).trim()
                        if (logResult) {
                            def logJson = readJSON(text: logResult)
                            logJson.events.each { event ->
                                echo event.message
                            }
                            nextToken = logJson.nextForwardToken ?: nextToken
                        }
                        buildStatus = sh(script: """
                            aws codebuild batch-get-builds --ids ${env.BUILD_ID} --region ${AWS_REGION} \
                            --query 'builds[0].buildStatus' --output text
                        """, returnStdout: true).trim()
                        echo "Build status: ${buildStatus}"
                    }
                    if (buildStatus == 'SUCCEEDED') {
                        echo '‚úÖ AWS CodeBuild completed successfully.'
                    } else {
                        error '‚ùå AWS CodeBuild failed.'
                    }
                }
            }
        }

        stage('Clone and Configure on Remote Host') {
            steps {
                script {
                    // Using SSH agent to run commands on the EC2 instance
                    def output = sshagent(credentials: [env.JENKINS_EC2_APP_SERVER_TWO]) {
                        sh(script: """
                            ssh -o StrictHostKeyChecking=no ${EC2_INSTANCE} '
                            set -e
                            BASE_DIR="${BASE_DIR}"
                            ENV="${env.ENVIRONMENT}"
                            TAG="${env.TAG_NAME}"
                            REPO_URL="${GIT_REPO}"
                            WORKSPACE_DIR="\$BASE_DIR/\$ENV"

                            echo "üöÄ Starting clone process for tag: \$TAG"
                            sudo mkdir -p "\$BASE_DIR"
                            sudo chown ubuntu:ubuntu "\$BASE_DIR"
                            mkdir -p "\$WORKSPACE_DIR"
                            cd "\$WORKSPACE_DIR"

                            echo "üîÑ Cloning repository for tag: \$TAG from \$REPO_URL"
                            TEMP_DIR=\$(mktemp -d)
                            git clone --branch "\$TAG" --depth 1 "\$REPO_URL" "\$TEMP_DIR" || { echo "‚ùå Error: Failed to clone tag \$TAG"; exit 1; }

                            echo "Logging into ECR"
                            AWS_ACCOUNT_ID=\$(aws sts get-caller-identity --query Account --output text)
                            ECR_URL="\${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPOSITORY}"
                            aws ecr get-login-password --region ${AWS_REGION} | docker login --username AWS --password-stdin \${ECR_URL}

                            if [ -z "${env.FRONTEND_SECRET_KEY}" ] || [ -z "${env.BACKEND_SECRET_KEY}" ]; then
                                echo "‚ùå Error: Failed to retrieve secrets from AWS S3. Please check the environment variables."
                                exit 1
                            fi

                            ##############################################################################
                            # Toggle logic for blue-green deployments
                            ##############################################################################
                            CURRENT_COLOR=\$(docker ps --filter "name=red-carpet_frontend_\${ENV}" --format "{{.Names}}" | grep -Eo "(blue|green)" | head -n 1)
                            if [ "\$CURRENT_COLOR" = "blue" ]; then
                                NEW_COLOR="green"
                                if [ "\$ENV" = "staging" ]; then
                                    HOST_FRONTEND_PORT=${STAGING_FRONTEND_SECONDARY_PORT}
                                    HOST_BACKEND_PORT=${STAGING_BACKEND_SECONDARY_PORT}
                                else
                                    HOST_FRONTEND_PORT=${FRONTEND_SECONDARY_PORT}
                                    HOST_BACKEND_PORT=${BACKEND_SECONDARY_PORT}
                                fi
                            elif [ "\$CURRENT_COLOR" = "green" ]; then
                                NEW_COLOR="blue"
                                if [ "\$ENV" = "staging" ]; then
                                    HOST_FRONTEND_PORT=${STAGING_FRONTEND_PORT}
                                    HOST_BACKEND_PORT=${STAGING_BACKEND_PORT}
                                else
                                    HOST_FRONTEND_PORT=${FRONTEND_PORT}
                                    HOST_BACKEND_PORT=${BACKEND_PORT}
                                fi
                            else
                                echo "No running container found. Defaulting to blue on primary ports."
                                NEW_COLOR="blue"
                                if [ "\$ENV" = "staging" ]; then
                                    HOST_FRONTEND_PORT=${STAGING_FRONTEND_PORT}
                                    HOST_BACKEND_PORT=${STAGING_BACKEND_PORT}
                                else
                                    HOST_FRONTEND_PORT=${FRONTEND_PORT}
                                    HOST_BACKEND_PORT=${BACKEND_PORT}
                                fi
                            fi

                            TARGET_DIR="\$WORKSPACE_DIR/\$NEW_COLOR"
                            mkdir -p "\$TARGET_DIR"
                            cp -f "\$TEMP_DIR/deployment/compose.yml" "\$TARGET_DIR/"
                            mkdir -p "\$TARGET_DIR/frontend"
                            mkdir -p "\$TARGET_DIR/backend"

                            echo "üö¶ Creating .env file in \$TARGET_DIR"
                            echo "üö¶ New deployment color: \$NEW_COLOR"
                            echo "üö¶ Host Frontend Port: \$HOST_FRONTEND_PORT"
                            echo "üö¶ Host Backend Port: \$HOST_BACKEND_PORT"
                            echo "üö¶ Target Directory: \$TARGET_DIR"

                            echo "üîë Fetching frontend .env from s3://${S3_ENV_BUCKET}/${env.FRONTEND_SECRET_KEY}"
                            aws s3 cp "s3://${S3_ENV_BUCKET}/${env.FRONTEND_SECRET_KEY}" "\$TARGET_DIR/frontend/.env" --region ${AWS_REGION} || exit 1

                            echo "üîë Fetching backend .env from s3://${S3_ENV_BUCKET}/${env.BACKEND_SECRET_KEY}"
                            aws s3 cp "s3://${S3_ENV_BUCKET}/${env.BACKEND_SECRET_KEY}" "\$TARGET_DIR/backend/.env" --region ${AWS_REGION} || exit 1

                            printf "AWS_ACCOUNT_ID=%s\\nAWS_REGION=%s\\nECR_REPOSITORY=%s\\nFRONTEND_TAG=%s\\nBACKEND_TAG=%s\\nHOST_FRONTEND_PORT=%s\\nHOST_BACKEND_PORT=%s\\nCOLOR=%s\\nENVIRONMENT=%s\\n" \\
                                "$AWS_ACCOUNT_ID" "$AWS_REGION" "$ECR_REPOSITORY" "$FRONTEND_TAG" "$BACKEND_TAG" "\$HOST_FRONTEND_PORT" "\$HOST_BACKEND_PORT" "\$NEW_COLOR" "\$ENV" > "\$TARGET_DIR/.env"

                            cd "\$TARGET_DIR"
                            docker-compose -f "\$TARGET_DIR/compose.yml" --env-file "\$TARGET_DIR/.env" pull || { echo "‚ùå Error: Failed to pull Docker images"; exit 1; }
                            echo "‚úÖ Successfully pulled latest Docker images."
                            rm -rf "\$TEMP_DIR"

                            # Force flush output before printing markers
                            sleep 1

                            echo "====VARIABLES_START===="
                            echo "WORKSPACE_DIR=\$WORKSPACE_DIR"
                            echo "CURRENT_COLOR=\$CURRENT_COLOR"
                            echo "NEW_COLOR=\$NEW_COLOR"
                            echo "HOST_FRONTEND_PORT=\$HOST_FRONTEND_PORT"
                            echo "HOST_BACKEND_PORT=\$HOST_BACKEND_PORT"
                            echo "TARGET_DIR=\$TARGET_DIR"
                            echo "====VARIABLES_END===="
                            '
                        """, returnStdout: true).trim()
                    }

                    echo "Full SSH output:\n${output}"

                    def startMarker = '====VARIABLES_START===='
                    def endMarker = '====VARIABLES_END===='
                    def markerBlock = ''
                    if (output.contains(startMarker) && output.contains(endMarker)) {
                        markerBlock = output.split(startMarker)[1].split(endMarker)[0].trim()
                    } else {
                        error('Could not find variable markers in the SSH output')
                    }
                    echo "Marker block:\n${markerBlock}"

                    def variables = [:]
                    for (line in markerBlock.split('\n')) {
                        if (line.contains('=')) {
                            def parts = line.split('=')
                            if (parts.size() >= 2) {
                                variables[parts[0].trim()] = parts[1].trim()
                            }
                        }
                    }

                    env.CURRENT_COLOR        = variables.CURRENT_COLOR
                    env.NEW_COLOR            = variables.NEW_COLOR
                    env.HOST_FRONTEND_PORT   = variables.HOST_FRONTEND_PORT
                    env.HOST_BACKEND_PORT    = variables.HOST_BACKEND_PORT
                    env.WORKSPACE_DIR        = variables.WORKSPACE_DIR
                    env.TARGET_DIR           = variables.TARGET_DIR

                    echo "Captured variables: ${variables}"
                }
            }
        }

        stage('Deploy Using Blue-Green Deployment') {
            steps {
                sshagent(credentials: [env.JENKINS_EC2_APP_SERVER_TWO]) {
                    // Use a unique compose project name (e.g., ENVIRONMENT_COLOR) to isolate deployments.
                    sh """
                        ssh -o StrictHostKeyChecking=no ${EC2_INSTANCE} '
                        set -e
                        PROJECT_NAME="${env.APP_NAME}_${env.ENVIRONMENT}_${env.NEW_COLOR}"
                        TARGET_DIR="${env.TARGET_DIR}"
                        echo "üöÄ Deploying to ${env.NEW_COLOR} environment with project: \$PROJECT_NAME in \$TARGET_DIR"
                        cd "\$TARGET_DIR"
                        echo "üìÇ Current directory: \$(pwd)"
                        echo "üìÑ Listing all files inside \$TARGET_DIR:"
                        ls -la
                        echo "üõ†Ô∏è Starting containers using Docker Compose with project name \$PROJECT_NAME..."
                        docker-compose -p "\$PROJECT_NAME" --env-file "\$TARGET_DIR/.env" -f "\$TARGET_DIR/compose.yml" up -d
                        echo "‚úÖ Deployment to \$TARGET_DIR completed!"
                        '
                    """
                }
            }
        }

        stage('Switch Nginx to New Deployment') {
            steps {
                sshagent(credentials: [env.JENKINS_EC2_APP_SERVER_TWO]) {
                    sh """
                        ssh -o StrictHostKeyChecking=no ${EC2_INSTANCE} '
                        set -e
                        ENV="${env.ENVIRONMENT}"

                                                CHECKS=0
                        MAX_CHECKS=5
                        set +e
                        while [ \$CHECKS -lt \$MAX_CHECKS ]; do
                            FRONTEND_STATUS=\$(curl -s -o /dev/null -w "%{http_code}" http://127.0.0.1:${env.HOST_FRONTEND_PORT}/$HEALTH_FRONTEND_PATH)
                            BACKEND_STATUS=\$(curl -s -o /dev/null -w "%{http_code}" http://127.0.0.1:${env.HOST_BACKEND_PORT}/$HEALTH_BACKEND_PATH/)
                            echo "Health check attempt \$((CHECKS+1)): Frontend=\$FRONTEND_STATUS, Backend=\$BACKEND_STATUS"
                            if [ "\$FRONTEND_STATUS" -eq 200 ] && [ "\$BACKEND_STATUS" -eq 200 ]; then
                                echo "‚úÖ Health check passed."
                                break
                            fi
                            CHECKS=\$((CHECKS+1))
                            sleep 1
                        done
                        set -e

                        echo "Using captured deploy info: Color=${env.NEW_COLOR}, Frontend Port=${env.HOST_FRONTEND_PORT}, Backend Port=${env.HOST_BACKEND_PORT}"
                        if [ "\$ENV" = "staging" ]; then
                            sudo sed -i "s/\\(server 127.0.0.1:\\)\\(${STAGING_FRONTEND_PORT}\\|${STAGING_FRONTEND_SECONDARY_PORT}\\)/\\1${env.HOST_FRONTEND_PORT}/" /etc/nginx/conf.d/$NGINX_STAGING_CONF
                            sudo sed -i "s/\\(server 127.0.0.1:\\)\\(${STAGING_BACKEND_PORT}\\|${STAGING_BACKEND_SECONDARY_PORT}\\)/\\1${env.HOST_BACKEND_PORT}/" /etc/nginx/conf.d/$NGINX_STAGING_CONF
                        else
                            sudo sed -i "s/\\(server 127.0.0.1:\\)\\(${FRONTEND_PORT}\\|${FRONTEND_SECONDARY_PORT}\\)/\\1${env.HOST_FRONTEND_PORT}/" /etc/nginx/conf.d/$NGINX_PRODUCTION_CONF
                            sudo sed -i "s/\\(server 127.0.0.1:\\)\\(${BACKEND_PORT}\\|${BACKEND_SECONDARY_PORT}\\)/\\1${env.HOST_BACKEND_PORT}/" /etc/nginx/conf.d/$NGINX_PRODUCTION_CONF
                        fi

                        if [ \$CHECKS -eq \$MAX_CHECKS ]; then
                            echo "‚ùå Health check failed after \$MAX_CHECKS attempts. Aborting Nginx reload."
                            exit 1
                        fi
                        sudo nginx -t
                        sudo systemctl reload nginx
                        echo "‚úÖ Nginx successfully reloaded with new configuration."
                        '
                    """
                }
            }
        }

        stage('Cleanup Old Containers') {
            steps {
                sshagent(credentials: [env.JENKINS_EC2_APP_SERVER_TWO]) {
                    sh """
                        ssh -o StrictHostKeyChecking=no ${EC2_INSTANCE} '
                        set -e
                        if [ "${env.CURRENT_COLOR}" = "blue" ]; then
                            INACTIVE_COLOR="blue"
                        elif [ "${env.CURRENT_COLOR}" = "green" ]; then
                            INACTIVE_COLOR="green"
                        else
                            echo "‚ö†Ô∏è No running container found to determine inactive deployment. Skipping cleanup."
                            exit 0
                        fi
                        PROJECT_NAME="${env.APP_NAME}_${env.ENVIRONMENT}_\$INACTIVE_COLOR"
                        INACTIVE_DIR="${env.WORKSPACE_DIR}/\$INACTIVE_COLOR"
                        if [ -d "\$INACTIVE_DIR" ]; then
                            echo "üóëÔ∏è Cleaning up old deployment: \$INACTIVE_COLOR with project \$PROJECT_NAME at \$INACTIVE_DIR"
                            cd "\$INACTIVE_DIR"
                            docker-compose -p "\$PROJECT_NAME" down || echo "Warning: Failed to bring down containers in \$INACTIVE_DIR"
                            docker system prune -af || echo "Warning: Failed to prune Docker system"
                            echo "‚úÖ Old deployment \$INACTIVE_COLOR cleaned up successfully!"
                        else
                            echo "‚ö†Ô∏è Directory \$INACTIVE_DIR does not exist. Skipping cleanup."
                        fi
                        '
                    """
                }
            }
        }

        stage('Notify & Finish') {
            steps {
                echo "‚úÖ Deployment successful! App is now running with tag: ${TAG_NAME}"
            }
        }
    }

    post {
        always {
            echo 'üîπ Job Finished'
        }
        success {
            echo '‚úÖ Build and Deployment Successful!'
        }
        failure {
            echo '‚ùå Build Failed! Check logs.'
        }
        unstable {
            echo '‚ö†Ô∏è Build is unstable! Review the warnings.'
        }
    }
}
